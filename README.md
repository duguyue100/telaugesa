# Telauges Alpha

I finally decided to rewrite my coding style for neural networks. This code will be eventually merged to Telauges.

This code is heavily referred to three deep learning library

+ [Pylearn2](https://github.com/lisa-lab/pylearn2)
+ [Blocks](https://github.com/mila-udem/blocks)
+ [theano_lstm](https://github.com/JonathanRaiman/theano_lstm)

## Requirements

General requirements can be achieved by `Anaconda`. More specifically, you need:

+ `python 2.7`
+ `numpy`
+ `scipy`
+ `theano`

## Supported Features

+ Feedfward Layer
   + Identity Layer
   + Tanh Layer
   + Sigmoid Layer
   + ReLU Layer
   + Softmax Layer (classification layer)
   + SVM [TODO]

+ ConvNet Layer
   + Identity Conv Layer
   + Tanh Conv Layer
   + Sigmoid Conv Layer
   + ReLU Conv Layer
   + Max-pooling Layer
   + Flatten Layer

+ Recurrent Neural Network
   + Simple Recurrent Net [TODO]
   + Long-Short Term Memory [TODO]
   + Gated Recurrent Net [TODO]

+ Training Algorithm
   + Stochastic gradient descent (SGD)
   + Adagrad [TODO]
   + Adadelta [TODO]
   + Dropout [TODO]

+ Model
   + Feedforward Model
   + Auto-encoder Model [TODO]
   + Convolutional Auto-encoder Model [TODO]
   + Mixed Layer Model [TODO]

## Contacts

Yuhuang Hu  
__No. 42, North, Flatland__  
Email: duguyue100@gmail.com
